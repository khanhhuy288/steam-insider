{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "db9545eb",
   "metadata": {},
   "source": [
    "### Steps\n",
    "- Use a list of **app_id** to get info from Steam crawler and insert **app_id**, **game_name**, **header_img_url**, **total_positive**, **total_negative**, **total_reviews** into table **games** and insert **game_id**, **review**, **recommended**, **time** into table **reviews**.\n",
    "- Preprocess **review** in table **reviews** (add_missing_punct, replace_bullets, remove_url, remove_html_tags, normalize_single_quote, remove_non_ascii, remove_ansi_escape_sequences, remove_multi_whitespaces), then tokenize_sent and remove_leading_symbols to insert **review_id**, **sent** into table **sents**. \n",
    "- Preprocess **sent** in table **sents** (lowercase, expand contractions, remove_digits, remove_symbols, remove_multi_whitespaces, lemmatize_text, remove_stopwords) to create **sent_prep** in table **sents**.\n",
    "- Use **sent_prep**, **review_id** in table **sents** to insert **review_prep** in table **reviews** by joining **sent_prep**.\n",
    "- Use **review_prep** in table **reviews** to calculate special bigrams frequency, get 50 most frequent keywords.\n",
    "- Insert **kw**, **freq** into table **kws**.\n",
    "- Embed 50 keywords using S-BERT and cluster them using agglomerative clustering with a distance_threshold=0.6. \n",
    "\t- Insert **cluster_name** (name of the most frequent keyword in cluster) into table **clusters**.\n",
    "\t- Insert **cluster_id** in table **kws**.\n",
    "- Loop through **sent_prep** in table **sents**, fuzzy-match each **kw** in table **kws**. \n",
    "    - Insert **cluster_id**, **sent_id** in table **clusters_sents**t to link table **clusters** and **sents**.\n",
    "- Remove all **sent_id** in table **sents** if they don't exist in table **clusters_sents**.\n",
    "    - Insert **score_flair**, **score_vader**, **recommended**, **score_total**, **sent_embedding** in table **sents**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d1c2602",
   "metadata": {},
   "source": [
    "### Step 1:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbc5a441",
   "metadata": {},
   "source": [
    "- Use a list of **app_id** to get info from Steam crawler and insert **app_id**, **game_name**, **header_img_url**, **total_positive**, **total_negative**, **total_reviews** into table **games** and insert **game_id** (fk), **review**, **recommended**, **time** into table **reviews**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "38323474",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import download_steam_reviews\n",
    "\n",
    "import sqlite3\n",
    "\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.cluster import AgglomerativeClustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "ac5ed95d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "80071b9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from contractions import contractions\n",
    "contractions = {\n",
    "    \"ain't\": \"is not\",\n",
    "    \"aren't\": \"are not\",\n",
    "    \"can't\": \"cannot\",\n",
    "    \"can't've\": \"cannot have\",\n",
    "    \"'cause\": \"because\",\n",
    "    \"could've\": \"could have\",\n",
    "    \"couldn't\": \"could not\",\n",
    "    \"couldn't've\": \"could not have\",\n",
    "    \"didn't\": \"did not\",\n",
    "    \"doesn't\": \"does not\",\n",
    "    \"don't\": \"do not\",\n",
    "    \"hadn't\": \"had not\",\n",
    "    \"hadn't've\": \"had not have\",\n",
    "    \"hasn't\": \"has not\",\n",
    "    \"haven't\": \"have not\",\n",
    "    \"he'd\": \"he would\",\n",
    "    \"he'd've\": \"he would have\",\n",
    "    \"he'll\": \"he will\",\n",
    "    \"he'll've\": \"he he will have\",\n",
    "    \"he's\": \"he is\",\n",
    "    \"how'd\": \"how did\",\n",
    "    \"how'd'y\": \"how do you\",\n",
    "    \"how'll\": \"how will\",\n",
    "    \"how's\": \"how is\",\n",
    "    \"i'd\": \"i would\",\n",
    "    \"i'd've\": \"i would have\",\n",
    "    \"i'll\": \"i will\",\n",
    "    \"i'll've\": \"i will have\",\n",
    "    \"i'm\": \"i am\",\n",
    "    \"i've\": \"i have\",\n",
    "    \"i'd\": \"i would\",\n",
    "    \"i'd've\": \"i would have\",\n",
    "    \"i'll\": \"i will\",\n",
    "    \"i'll've\": \"i will have\",\n",
    "    \"i'm\": \"i am\",\n",
    "    \"i've\": \"i have\",\n",
    "    \"isn't\": \"is not\",\n",
    "    \"it'd\": \"it would\",\n",
    "    \"it'd've\": \"it would have\",\n",
    "    \"it'll\": \"it will\",\n",
    "    \"it'll've\": \"it will have\",\n",
    "    \"it's\": \"it is\",\n",
    "    \"let's\": \"let us\",\n",
    "    \"ma'am\": \"madam\",\n",
    "    \"mayn't\": \"may not\",\n",
    "    \"might've\": \"might have\",\n",
    "    \"mightn't\": \"might not\",\n",
    "    \"mightn't've\": \"might not have\",\n",
    "    \"must've\": \"must have\",\n",
    "    \"mustn't\": \"must not\",\n",
    "    \"mustn't've\": \"must not have\",\n",
    "    \"needn't\": \"need not\",\n",
    "    \"needn't've\": \"need not have\",\n",
    "    \"o'clock\": \"of the clock\",\n",
    "    \"oughtn't\": \"ought not\",\n",
    "    \"oughtn't've\": \"ought not have\",\n",
    "    \"shan't\": \"shall not\",\n",
    "    \"sha'n't\": \"shall not\",\n",
    "    \"shan't've\": \"shall not have\",\n",
    "    \"she'd\": \"she would\",\n",
    "    \"she'd've\": \"she would have\",\n",
    "    \"she'll\": \"she will\",\n",
    "    \"she'll've\": \"she will have\",\n",
    "    \"she's\": \"she is\",\n",
    "    \"should've\": \"should have\",\n",
    "    \"shouldn't\": \"should not\",\n",
    "    \"shouldn't've\": \"should not have\",\n",
    "    \"so've\": \"so have\",\n",
    "    \"so's\": \"so as\",\n",
    "    \"that'd\": \"that would\",\n",
    "    \"that'd've\": \"that would have\",\n",
    "    \"that's\": \"that is\",\n",
    "    \"there'd\": \"there would\",\n",
    "    \"there'd've\": \"there would have\",\n",
    "    \"there's\": \"there is\",\n",
    "    \"they'd\": \"they would\",\n",
    "    \"they'd've\": \"they would have\",\n",
    "    \"they'll\": \"they will\",\n",
    "    \"they'll've\": \"they will have\",\n",
    "    \"they're\": \"they are\",\n",
    "    \"they've\": \"they have\",\n",
    "    \"to've\": \"to have\",\n",
    "    \"wasn't\": \"was not\",\n",
    "    \"we'd\": \"we would\",\n",
    "    \"we'd've\": \"we would have\",\n",
    "    \"we'll\": \"we will\",\n",
    "    \"we'll've\": \"we will have\",\n",
    "    \"we're\": \"we are\",\n",
    "    \"we've\": \"we have\",\n",
    "    \"weren't\": \"were not\",\n",
    "    \"what'll\": \"what will\",\n",
    "    \"what'll've\": \"what will have\",\n",
    "    \"what're\": \"what are\",\n",
    "    \"what's\": \"what is\",\n",
    "    \"what've\": \"what have\",\n",
    "    \"when's\": \"when is\",\n",
    "    \"when've\": \"when have\",\n",
    "    \"where'd\": \"where did\",\n",
    "    \"where's\": \"where is\",\n",
    "    \"where've\": \"where have\",\n",
    "    \"who'll\": \"who will\",\n",
    "    \"who'll've\": \"who will have\",\n",
    "    \"who's\": \"who is\",\n",
    "    \"who've\": \"who have\",\n",
    "    \"why's\": \"why is\",\n",
    "    \"why've\": \"why have\",\n",
    "    \"will've\": \"will have\",\n",
    "    \"won't\": \"will not\",\n",
    "    \"won't've\": \"will not have\",\n",
    "    \"would've\": \"would have\",\n",
    "    \"wouldn't\": \"would not\",\n",
    "    \"wouldn't've\": \"would not have\",\n",
    "    \"y'all\": \"you all\",\n",
    "    \"y'all'd\": \"you all would\",\n",
    "    \"y'all'd've\": \"you all would have\",\n",
    "    \"y'all're\": \"you all are\",\n",
    "    \"y'all've\": \"you all have\",\n",
    "    \"you'd\": \"you would\",\n",
    "    \"you'd've\": \"you would have\",\n",
    "    \"you'll\": \"you will\",\n",
    "    \"you'll've\": \"you will have\",\n",
    "    \"you're\": \"you are\",\n",
    "    \"you've\": \"you have\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f11a1a99",
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = sqlite3.connect('./data/steam_reviews.db') \n",
    "cursor = conn.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a79ebfd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_cursor(cursor): \n",
    "    print(cursor.execute(\"\"\"\n",
    "        select * from games;\n",
    "    \"\"\").fetchall())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52bc36a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_cursor(cursor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "717e23e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cursor.execute(\"\"\"\n",
    "        select game_id from games \n",
    "        where app_id=367520;\n",
    "    \"\"\").fetchall()[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b80fb766",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 428550 - Momodora: Reverie under the Moonlight\n",
    "# 367520 - Hollow Knight\n",
    "app_ids = [428550, 367520]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0f35a569",
   "metadata": {},
   "outputs": [],
   "source": [
    "### get game_name ###\n",
    "\n",
    "def get_app_list(): \n",
    "    app_list_url = 'https://api.steampowered.com/ISteamApps/GetAppList/v2/'\n",
    "    resp_data = requests.get(app_list_url)\n",
    "    return resp_data.json()\n",
    "\n",
    "def get_name(app_id, app_list): \n",
    "    for app in app_list['applist']['apps']: \n",
    "        if app['appid'] == app_id: \n",
    "            return app['name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "78465edf",
   "metadata": {},
   "outputs": [],
   "source": [
    "### get header_img_url  \n",
    "\n",
    "def get_header_img_url(app_id): \n",
    "    return f'https://cdn.cloudflare.steamstatic.com/steam/apps/{app_id}/header.jpg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6d7fbf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "### get total_positive, total_negative, total_reviews in Crawler for table games \n",
    "### get game_id, review, recommended, time in Crawler for table games \n",
    "\n",
    "app_list = get_app_list()\n",
    "\n",
    "request_params = {\n",
    "    'language': 'english'\n",
    "}\n",
    "\n",
    "# load or download new (maximum ~5000 newest reviews)\n",
    "load_mode = True\n",
    "\n",
    "for app_id in app_ids: \n",
    "    game_tuples = [] \n",
    "\n",
    "    game_name = get_name(app_id, app_list)\n",
    "    \n",
    "    header_img_url = get_header_img_url(app_id)\n",
    "    \n",
    "    total_positive, total_negative, total_reviews = 0, 0, 0\n",
    "    \n",
    "    if load_mode: \n",
    "        review_dict = download_steam_reviews.load_review_dict(app_id)['reviews'].values()\n",
    "    else: \n",
    "        review_dict = download_steam_reviews.download_reviews_for_app_id(app_id, \n",
    "                                                                     chosen_request_params=request_params, \n",
    "                                                                     reviews_limit=5000)[0]['reviews'].values()\n",
    "    \n",
    "    review_tuples = []\n",
    "    \n",
    "    with conn:\n",
    "        cursor.execute(\"\"\"INSERT INTO games (app_id, game_name, header_img_url) VALUES (?, ?, ?);\"\"\", \n",
    "                       (app_id, game_name, header_img_url))\n",
    "    \n",
    "    # get game_id (fk) for table reviews\n",
    "    game_id = cursor.execute(\"\"\"SELECT game_id FROM games WHERE app_id=?;\"\"\", (app_id,)).fetchone()[0] \n",
    "    \n",
    "    for review_dict_value in review_dict: \n",
    "        total_reviews += 1\n",
    "    \n",
    "        voted_up = 1 if review_dict_value['voted_up'] else 0\n",
    "    \n",
    "        if voted_up: \n",
    "            total_positive += 1\n",
    "        else: \n",
    "            total_negative += 1\n",
    "     \n",
    "        review = review_dict_value['review']\n",
    "        recommended = voted_up\n",
    "        time = review_dict_value['timestamp_updated']\n",
    "        \n",
    "        review_tuples.append((review, recommended, time, game_id))\n",
    "    \n",
    "    with conn:\n",
    "        cursor.execute(\"\"\"UPDATE games SET (total_positive, total_negative, total_reviews) = (?, ?, ?)\n",
    "                            WHERE game_id=?;\"\"\",\n",
    "                       (total_positive, total_negative, total_reviews, game_id))\n",
    "    \n",
    "    with conn:\n",
    "        cursor.executemany(\"\"\"INSERT INTO reviews (review, recommended, time, game_id) VALUES \n",
    "                                (?, ?, ?, ?);\"\"\", review_tuples)    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4f39413",
   "metadata": {},
   "source": [
    "### Step 2:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c05092c7",
   "metadata": {},
   "source": [
    "- Preprocess **review** in table **reviews** (add_missing_punct, replace_bullets, remove_url, remove_html_tags, normalize_single_quote, remove_non_ascii, remove_ansi_escape_sequences, remove_multi_whitespaces), then tokenize_sent and remove_leading_symbols to insert **review_id**, **sent** into table **sents**. \n",
    "- Preprocess **sent** in table **sents** (lowercase, expand contractions, remove_digits, remove_symbols, remove_multi_whitespaces, lemmatize_text, remove_stopwords) to insert **sent_prep** in table **sents**.\n",
    "- Use **sent_prep**, **review_id** in table **sents** to insert **review_prep** in table **reviews** by joining **sent_prep**.\n",
    "        \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ada075ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reviews = pd.read_sql_query(\"\"\"SELECT review_id, review, game_id \n",
    "                    FROM reviews JOIN games USING(game_id);\"\"\", conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ce5d3e04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_id</th>\n",
       "      <th>review</th>\n",
       "      <th>game_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Metroidvania with some influences from Dark So...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>It's ok. Frustrating mechanics turned me off o...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Cat</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Has problems but overall pretty good. I'd sugg...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>This is a very good and very short game. If yo...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8825</th>\n",
       "      <td>8826</td>\n",
       "      <td>it's ok</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8826</th>\n",
       "      <td>8827</td>\n",
       "      <td>One of the most polished and engaging games I'...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8827</th>\n",
       "      <td>8828</td>\n",
       "      <td>ahem\\n\"very hard owo\"</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8828</th>\n",
       "      <td>8829</td>\n",
       "      <td>this game sic</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8829</th>\n",
       "      <td>8830</td>\n",
       "      <td>DOMA DOMA DOMA DOMA DOMA</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8830 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      review_id                                             review  game_id\n",
       "0             1  Metroidvania with some influences from Dark So...        1\n",
       "1             2  It's ok. Frustrating mechanics turned me off o...        1\n",
       "2             3                                                Cat        1\n",
       "3             4  Has problems but overall pretty good. I'd sugg...        1\n",
       "4             5  This is a very good and very short game. If yo...        1\n",
       "...         ...                                                ...      ...\n",
       "8825       8826                                            it's ok        2\n",
       "8826       8827  One of the most polished and engaging games I'...        2\n",
       "8827       8828                              ahem\\n\"very hard owo\"        2\n",
       "8828       8829                                      this game sic        2\n",
       "8829       8830                           DOMA DOMA DOMA DOMA DOMA        2\n",
       "\n",
       "[8830 rows x 3 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a076f4f5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fbfa4f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "de03b913",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_missing_punct(text): \n",
    "    return re.sub('([A-Za-z0-9])\\s*$', '\\g<1>. ', text)\n",
    "\n",
    "\n",
    "def replace_bullets(text): \n",
    "    text = re.sub('([A-Za-z0-9])\\s*\\n+\\s*[+-]?\\s*', '\\g<1>. ', text)\n",
    "    text = re.sub('\\s*([:+-]+)\\s*\\n+\\s*[+-]?\\s*', '. ', text) \n",
    "    return text\n",
    "    \n",
    "    \n",
    "# remove url from text\n",
    "def remove_url(text):\n",
    "    return re.sub(r\"http\\S+\", ' ', text)\n",
    "\n",
    "\n",
    "# remove HTML tags\n",
    "def remove_html_tags(text):\n",
    "    soup = BeautifulSoup(text, \"lxml\")\n",
    "    text = soup.get_text()\n",
    "    # remove square brackets and characters inside\n",
    "    text = re.sub('\\[(.*?)\\]', ' ', text)\n",
    "    return text\n",
    "\n",
    "\n",
    "# replace ’ with ' \n",
    "def normalize_single_quote(text):\n",
    "    return re.sub('[’‘]', '\\'', text)\n",
    "\n",
    "\n",
    "# remove non english characters effectively\n",
    "def remove_non_ascii(text): \n",
    "    return text.encode(\"ascii\", errors=\"ignore\").decode()\n",
    "    \n",
    "    \n",
    "# remove ANSI escape sequences\n",
    "def remove_ansi_escape_sequences(text):\n",
    "    ansi_escape = re.compile(r'(?:\\x1B[@-_]|[\\x80-\\x9F])[0-?]*[ -/]*[@-~]')\n",
    "    return ansi_escape.sub('', text)\n",
    "    \n",
    "    \n",
    "# remove multiple whitespaces with single whitespace\n",
    "def remove_multi_whitespaces(text): \n",
    "    return re.sub('\\s+', ' ', text.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0510427c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_leading_symbols(sent):\n",
    "    return re.sub('^[^A-Za-z\\\"\\'\\d]+', '', sent)\n",
    "\n",
    "def uppercase_first(sent): \n",
    "    return sent[0].upper() + sent[1:] if len(sent) != 0 else sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ddb6cfec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_sent(text):\n",
    "    doc = nlp(text, disable=['ner', 'attribute_ruler', 'lemmatizer', 'sentencizer'])\n",
    "    sents = [str(sent).strip() for sent in doc.sents]\n",
    "    return sents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4abfc963",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lowercase(text):\n",
    "    return text.lower()\n",
    "\n",
    "def expand_contractions(text):\n",
    "    for key in contractions:\n",
    "        value = contractions[key]\n",
    "        text = text.replace(key, value)\n",
    "    return text\n",
    "\n",
    "# remove digits \n",
    "def remove_digits(text): \n",
    "    return re.sub('\\d+', ' ', text)\n",
    "\n",
    "# remove symbols \n",
    "def remove_symbols(text):\n",
    "    return re.sub('[^A-Za-z,.\\s\\d]+', ' ', text)\n",
    "\n",
    "# lemmatization with spacy \n",
    "def lemmatize_text(text): \n",
    "    doc = nlp(text, disable=['parser','ner'])\n",
    "    lemma = [token.lemma_ for token in doc if token.pos_ != 'PUNCT']\n",
    "    return ' '.join(lemma)\n",
    "\n",
    "# remove stop words \n",
    "def remove_stopwords(text, word_list=[]):\n",
    "    stop_words = stopwords.words(\"english\")\n",
    "    stop_words.extend(word_list)\n",
    "    stop_words = set(stop_words)\n",
    "    return ' '.join(e.lower() for e in text.split() if e.lower() not in stop_words)\n",
    "\n",
    "def get_extra_stopwords(game_name): \n",
    "    stopwords = set(['game'])\n",
    "    doc = nlp(game_name.lower(), disable=['parser', 'ner'])\n",
    "    for token in doc: \n",
    "        if token.pos_ not in {'PUNCT', 'NUM'}:\n",
    "            stopwords.add(token.text)\n",
    "    return stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "731c26a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\envs\\steam_insider\\lib\\site-packages\\bs4\\__init__.py:336: MarkupResemblesLocatorWarning: \".\" looks like a filename, not markup. You should probably open this file and pass the filehandle into Beautiful Soup.\n",
      "  MarkupResemblesLocatorWarning\n",
      "D:\\Anaconda3\\envs\\steam_insider\\lib\\site-packages\\bs4\\__init__.py:336: MarkupResemblesLocatorWarning: \" .\" looks like a filename, not markup. You should probably open this file and pass the filehandle into Beautiful Soup.\n",
      "  MarkupResemblesLocatorWarning\n",
      "D:\\Anaconda3\\envs\\steam_insider\\lib\\site-packages\\ipykernel_launcher.py:22: DeprecationWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "D:\\Anaconda3\\envs\\steam_insider\\lib\\site-packages\\bs4\\__init__.py:336: MarkupResemblesLocatorWarning: \"...\" looks like a filename, not markup. You should probably open this file and pass the filehandle into Beautiful Soup.\n",
      "  MarkupResemblesLocatorWarning\n",
      "D:\\Anaconda3\\envs\\steam_insider\\lib\\site-packages\\bs4\\__init__.py:336: MarkupResemblesLocatorWarning: \".\" looks like a filename, not markup. You should probably open this file and pass the filehandle into Beautiful Soup.\n",
      "  MarkupResemblesLocatorWarning\n",
      "D:\\Anaconda3\\envs\\steam_insider\\lib\\site-packages\\bs4\\__init__.py:336: MarkupResemblesLocatorWarning: \"/\" looks like a filename, not markup. You should probably open this file and pass the filehandle into Beautiful Soup.\n",
      "  MarkupResemblesLocatorWarning\n",
      "D:\\Anaconda3\\envs\\steam_insider\\lib\\site-packages\\ipykernel_launcher.py:22: DeprecationWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n"
     ]
    }
   ],
   "source": [
    "sent_tuples = []\n",
    "\n",
    "for game_id in df_reviews['game_id'].unique():\n",
    "    with conn: \n",
    "        game_name = cursor.execute(\"\"\"SELECT game_name FROM games WHERE game_id=?;\"\"\", (int(game_id),)).fetchone()[0]\n",
    "    \n",
    "    extra_stopwords = get_extra_stopwords(game_name)\n",
    "    \n",
    "    df_reviews_game = df_reviews[df_reviews['game_id'] == game_id]\n",
    "    \n",
    "    reviews_game_cleaned = df_reviews_game['review'].map(add_missing_punct)\\\n",
    "                    .map(replace_bullets)\\\n",
    "                    .map(remove_url)\\\n",
    "                    .map(remove_html_tags)\\\n",
    "                    .map(normalize_single_quote)\\\n",
    "                    .map(remove_non_ascii)\\\n",
    "                    .map(remove_ansi_escape_sequences)\\\n",
    "                    .map(remove_multi_whitespaces)\n",
    "    \n",
    "    for review_id, review in zip(df_reviews_game['review_id'], reviews_game_cleaned):\n",
    "        sents = pd.Series(tokenize_sent(review)).map(remove_leading_symbols)\\\n",
    "                                                .map(uppercase_first)\\\n",
    "                                                .map(add_missing_punct)\\\n",
    "                                                .map(remove_multi_whitespaces)\n",
    "\n",
    "        sents_prep = sents.map(lowercase)\\\n",
    "                        .map(expand_contractions)\\\n",
    "                        .map(remove_digits)\\\n",
    "                        .map(remove_symbols)\\\n",
    "                        .map(remove_multi_whitespaces)\\\n",
    "                        .map(lemmatize_text)\\\n",
    "                        .map(lambda x: remove_stopwords(x, word_list=extra_stopwords))\n",
    "\n",
    "        for sent, sent_prep in zip(sents, sents_prep):\n",
    "            sent_tuples.append((review_id, sent, sent_prep))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "1cde9cde",
   "metadata": {},
   "outputs": [],
   "source": [
    "with conn:\n",
    "    cursor.executemany(\"\"\"INSERT INTO sents (review_id, sent, sent_prep) VALUES \n",
    "                        (?, ?, ?);\"\"\", sent_tuples)    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dad82bd5",
   "metadata": {},
   "source": [
    "### Step 3: \n",
    "- Use **review_prep** in table **reviews** to calculate special bigrams frequency, get 50 most frequent keywords.\n",
    "- Insert **kw**, **freq** into table **kws**.\n",
    "- Embed 50 keywords using S-BERT and cluster them using agglomerative clustering with a distance_threshold=0.6. \n",
    "\t- Insert **cluster_name** (name of the most frequent keyword in cluster) into table **clusters**.\n",
    "\t- Insert **cluster_id** in table **kws**.\n",
    "- Loop through **sent_prep** in table **sents**, fuzzy-match each **kw** in table **kws**. \n",
    "    - Insert **cluster_id**, **sent_id** in table **clusters_sents** to link table **clusters** and **sents**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "a1e4d146",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_n_gram(x, ngram, min_df=1):\n",
    "    vec = CountVectorizer(ngram_range=[ngram, ngram], min_df=min_df).fit(x)\n",
    "    bow = vec.transform(x)\n",
    "    sum_words = bow.sum(axis = 0)\n",
    "    words_freq = [(word, sum_words[0, idx]) for word, idx in vec.vocabulary_.items()]\n",
    "    words_freq = sorted(words_freq, key = lambda x: x[1], reverse = True)\n",
    "    return words_freq\n",
    "\n",
    "def bigramRules(bigram): \n",
    "    first_pos = set(['ADJ', 'NOUN'])\n",
    "    second_pos = set(['NOUN'])\n",
    "    \n",
    "    tags = [token.pos_ for token in nlp(bigram, disable=['parser','ner'])]\n",
    "    \n",
    "    return tags[0] in first_pos and tags[1] in second_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "52ef7079",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sent_prep = pd.read_sql_query(\"\"\"SELECT sent_prep, game_id\n",
    "                    FROM sents JOIN reviews USING(review_id) JOIN games USING(game_id);\"\"\", conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "a49b9bb9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sent_prep</th>\n",
       "      <th>game_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>metroidvania influence dark soul</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>enjoy</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>check guide see true ending</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ok</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>frustrating mechanic turn</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35011</th>\n",
       "      <td>one polished engaging play</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35012</th>\n",
       "      <td>ahem</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35013</th>\n",
       "      <td>hard owo</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35014</th>\n",
       "      <td>sic</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35015</th>\n",
       "      <td>doma doma doma doma doma</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>35016 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              sent_prep  game_id\n",
       "0      metroidvania influence dark soul        1\n",
       "1                                 enjoy        1\n",
       "2           check guide see true ending        1\n",
       "3                                    ok        1\n",
       "4             frustrating mechanic turn        1\n",
       "...                                 ...      ...\n",
       "35011        one polished engaging play        2\n",
       "35012                              ahem        2\n",
       "35013                          hard owo        2\n",
       "35014                               sic        2\n",
       "35015          doma doma doma doma doma        2\n",
       "\n",
       "[35016 rows x 2 columns]"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sent_prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "785818ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "sents_prep = df_sent_prep[df_sent_prep['game_id'] == 1]['sent_prep']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "57618ab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "bigram = get_n_gram(sents_prep, 2, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "e1d1c5f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "bigram_df = pd.DataFrame(bigram, columns=['bigram', 'freq'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "86644357",
   "metadata": {},
   "outputs": [],
   "source": [
    "bigram_df_50 = []\n",
    "count = 0\n",
    "for bigram, freq in zip(bigram_df['bigram'], bigram_df['freq']): \n",
    "    if bigramRules(bigram):\n",
    "        bigram_df_50.append((bigram, freq))\n",
    "        \n",
    "        count += 1\n",
    "        \n",
    "        if count == 50: \n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "3d8e45b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "bigram_df = pd.DataFrame(bigram_df_50, columns=['bigram', 'freq'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "5fb86f5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "kws = bigram_df['bigram']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "832a3a35",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedder = SentenceTransformer('paraphrase-MiniLM-L6-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "3ae044e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "kw_embeddings = embedder.encode(keywords)\n",
    "\n",
    "# Normalize the embeddings to unit length\n",
    "kw_embeddings = kw_embeddings /  np.linalg.norm(kw_embeddings, axis=1, keepdims=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "ccd36340",
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform agglomerative clustering\n",
    "clustering_model = AgglomerativeClustering(n_clusters=None, affinity='cosine', linkage='average', distance_threshold=0.6)\n",
    "clustering_model.fit(kw_embeddings)\n",
    "cluster_assignment = clustering_model.labels_\n",
    "\n",
    "kw_clusters = {}\n",
    "for kw_id, cluster_id in enumerate(cluster_assignment):\n",
    "    if cluster_id not in kw_clusters:\n",
    "        kw_clusters[cluster_id] = []\n",
    "\n",
    "    kw_clusters[cluster_id].append(kws[kw_id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "ebf40d12",
   "metadata": {},
   "outputs": [],
   "source": [
    "bigram_df['cluster_num'] = cluster_assignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "f1d1c51a",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_tuples = []\n",
    "for cluster_num, cluster_val in kw_clusters.items():\n",
    "    cluster_tuples.append((game_id, int(cluster_num), cluster_val[0]))\n",
    "    \n",
    "kw_tuples = []\n",
    "for kw, freq, cluster_num in zip(bigram_df['bigram'], bigram_df['freq'], bigram_df['cluster_num']):\n",
    "    kw_tuples.append((kw, freq, cluster_num, game_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "68843e6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "with conn:\n",
    "    cursor.executemany(\"\"\"INSERT INTO clusters (game_id, cluster_num, cluster_name) VALUES \n",
    "                        (?, ?, ?);\"\"\", cluster_tuples)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "23b6be6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "with conn:\n",
    "    cursor.executemany(\"\"\"INSERT INTO kws (kw, freq, cluster_id) VALUES \n",
    "                        (?, ?, (SELECT cluster_id FROM clusters WHERE cluster_num=? AND game_id=?));\"\"\",\n",
    "                       kw_tuples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "ec32114c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46c77cc8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ad3a6f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d76b5ea5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d99f2d1f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98d693b1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a4109b3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Steam Insider",
   "language": "python",
   "name": "steam_insider"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
